# Root Cause Found: TorchScript Tracing Issue ‚úÖ

**Date:** 2025-11-07
**Commit:** b3405a3

---

## The Real Problem üêõ

The validation shows **CasADi doesn't match PyTorch** (12 MW vs 4.8 MW). This is NOT a double-normalization issue - it's a **TorchScript tracing issue**.

### Root Cause

**In `surrogate_module/model.py`:**
```python
def forward(self, x: torch.Tensor, normalized: bool = False) -> torch.Tensor:
    if not normalized:  # ‚ùå CONDITIONAL LOGIC
        x = self.normalize_input(x)  # Uses register_buffer

    y = self.network(x)
    y = self.denormalize_output(y)  # Uses register_buffer
    return y
```

**Problem:**
1. l4casadi uses **TorchScript** to convert PyTorch ‚Üí CasADi
2. TorchScript **can't properly trace**:
   - Conditional logic (`if not normalized:`)
   - Operations on `register_buffer` tensors
3. Result: l4casadi exports the network but **loses the normalization**
4. CasADi function expects **normalized** inputs (not raw)
5. We pass raw inputs ‚Üí wrong predictions!

### Why It Fails

When l4casadi traces the model:
```python
# l4casadi internally does:
traced_model = torch.jit.trace(model, example_input)
```

TorchScript tracing:
- ‚úÖ Traces the path taken during example forward pass
- ‚ùå Doesn't capture conditional branches
- ‚ùå Doesn't properly handle register_buffer operations
- Result: Normalization code is lost or broken

---

## The Solution ‚úÖ

### Created: `export_l4casadi_model_v2.py`

**Key Innovation:** Simple wrapper without conditionals:

```python
class SimplePowerSurrogate(nn.Module):
    """
    Simplified wrapper for l4casadi export.
    No conditional logic - always normalizes/denormalizes.
    """

    def __init__(self, original_model: PowerSurrogate):
        super().__init__()

        # Copy network
        self.network = original_model.network

        # Copy normalization as regular tensors (not buffers!)
        self.input_mean = original_model.input_mean.clone()
        self.input_std = original_model.input_std.clone()
        self.output_mean = original_model.output_mean.clone()
        self.output_std = original_model.output_std.clone()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Simple forward - no conditionals, explicit operations.
        TorchScript can properly trace this!
        """
        # Normalize
        x_norm = (x - self.input_mean) / (self.input_std + 1e-8)

        # Network
        y_norm = self.network(x_norm)

        # Denormalize
        y = y_norm * self.output_std + self.output_mean

        return y
```

**Why This Works:**
- ‚úÖ No conditional logic
- ‚úÖ All operations are explicit and traceable
- ‚úÖ Normalization parameters are regular tensors (not buffers)
- ‚úÖ TorchScript can properly trace the entire computation graph
- ‚úÖ l4casadi exports everything correctly

---

## Fix Steps

### 1. Re-export the model with the fixed script
```bash
cd ~/Documents/mpcrl/alternative_approach
python scripts/export_l4casadi_model_v2.py
```

**Expected output:**
```
======================================================================
L4CasADi Model Export (V2 - Fixed)
======================================================================

Loading model from checkpoints/power_surrogate_best.ckpt...
  ‚úÖ Model loaded and wrapped
  Parameters: X,XXX

Validating wrapper...
  Max absolute difference: 0.00 kW
  Mean absolute difference: 0.00 kW
  ‚úÖ Wrapper matches original perfectly!

Exporting to l4casadi...
  ‚úÖ CasADi function created
  ‚úÖ Saved to models/power_surrogate_casadi.pkl

Validating export...
  Testing 100 random samples...

  Results:
    Max absolute difference: 0.05 kW
    Mean absolute difference: 0.02 kW
    Max relative difference: 0.0001%
    Mean relative difference: 0.0000%
  ‚úÖ Validation passed!

======================================================================
‚úÖ Export complete!
======================================================================
```

### 2. Validate the fix
```bash
python validate_normalization.py
```

**Expected:**
```
‚úÖ CasADi export is working correctly!
   Error is negligible (< 100 W)
```

### 3. Run MPC
```bash
python nmpc_surrogate_casadi.py
```

**Expected:**
- Solver converges
- Finds optimal yaw angles (NOT [0, 0, 0, 0])
- Power increases ~15% vs baseline

---

## Technical Details

### Why TorchScript Fails with Original Model

**Problem 1: Conditional Logic**
```python
if not normalized:
    x = self.normalize_input(x)
```
- TorchScript traces ONE path during export
- It doesn't capture both branches
- Result: Either always normalizes or never normalizes (depending on trace)

**Problem 2: register_buffer Operations**
```python
self.register_buffer('input_mean', torch.zeros(input_dim))

def normalize_input(self, x):
    return (x - self.input_mean) / (self.input_std + 1e-8)
```
- register_buffer creates non-trainable tensors
- TorchScript has known issues tracking these operations
- Operations might not be properly included in traced graph

### Why SimplePowerSurrogate Works

**Fix 1: No Conditionals**
```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    # Always do the same operations - no if statements!
    x_norm = (x - self.input_mean) / (self.input_std + 1e-8)
    y_norm = self.network(x_norm)
    y = y_norm * self.output_std + self.output_mean
    return y
```
- Single execution path
- TorchScript traces everything

**Fix 2: Regular Tensors**
```python
# Not register_buffer - just regular tensors!
self.input_mean = original_model.input_mean.clone()
self.input_std = original_model.input_std.clone()
```
- Regular tensors are properly traced
- All operations are captured in the graph

---

## Alternative Solutions (Not Used)

### Option 1: Use torch.jit.script instead of trace ‚ùå
```python
scripted_model = torch.jit.script(model)
```
**Pros:** Can handle conditionals
**Cons:** l4casadi uses tracing internally, can't change it

### Option 2: Modify original model ‚ùå
**Pros:** Clean solution
**Cons:** Would break existing training code

### Option 3: Wrapper model (CHOSEN) ‚úÖ
**Pros:**
- Doesn't modify original model
- Simple and traceable
- Works with existing training code
**Cons:**
- Slight code duplication

---

## Validation Strategy

The new export script validates in 3 steps:

**Step 1: Wrapper vs Original**
- Ensures SimplePowerSurrogate matches PowerSurrogate
- Tests 100 random inputs
- Should be < 1 W difference

**Step 2: CasADi vs Wrapper**
- Ensures l4casadi export matches wrapper
- Tests 100 random inputs
- Should be < 1 kW difference

**Step 3: Manual validation**
- User runs validate_normalization.py
- Tests specific cases
- Should show < 100 W error

---

## Summary

**Original Issue:** PyTorch model has conditional logic that TorchScript can't trace
**Solution:** Simple wrapper without conditionals for l4casadi export
**Next Step:** Re-export model with `export_l4casadi_model_v2.py`

---

## After Re-Export

Once you've re-exported the model, the full pipeline should work:

1. **Dataset generation** ‚úÖ (already done)
2. **Model training** ‚úÖ (already done)
3. **L4CasADi export** ‚úÖ (NOW FIXED!)
4. **MPC optimization** ‚è≥ (should work after re-export)

---

**Status:** Root cause identified, fix implemented
**Action:** Run `python scripts/export_l4casadi_model_v2.py`
**Expected:** Perfect match between PyTorch and CasADi (< 100 W error)
